{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFD Modeling Process\n",
    "\n",
    "Let's start by talking about what a CFD is? A Contract For Difference(CFD) is essentially a financial derivative, which means that its value depends on the value of a subjacent asset, for the purpose of this exercise, the subjacent asset will be a stock. \n",
    "\n",
    "Now the price of a CFD contract its determined by the difference of the current, and time of contract value of the subjacent asset. In a CFD negotiation there are two parts, buyer and seller, the buyer will pay to the seller the difference between the current value of an asset and its value at contract time, if the difference is negative the seller will pay the buyer.\n",
    "\n",
    "This leads us to part of interest for this project, we want to know in advance which position will make money i.e. if the asset value will be larger than the future value or less for we to take the seller or buyer position, also would be benefitial to know what are going to be the extreme values of the asset to know the max liquidation risk and also the moment when the position should be close for maximum profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necesary Steps:\n",
    "\n",
    "The notebook is going to be mainly divided in this steps for the modeling process.\n",
    "\n",
    "1. Build features and objective variables within the data.\n",
    "2. Build ML pipeline and model selection.\n",
    "3. Additional Features.\n",
    "4. Model optimization.\n",
    "5. Save Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Features and Objective Variables.\n",
    "\n",
    "As stated in the intro we are interested in three variables, a classification to know whether the value of an `asset will rise or fall`, the `maximum value` the asset will take and the `minimum value` it will take. All of this depends of the time window we consider, so it is necesary to make that definition, for now we are going to stick with a `3 month` window.\n",
    "\n",
    "We are going to define this process for one stock and then extend it to the rest of the stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///'+'stock_price.db')\n",
    "\n",
    "df_d = pd.read_sql_table('FCEL_daily', engine)\n",
    "df_w = pd.read_sql_table('FCEL_weekly', engine)\n",
    "df_m = pd.read_sql_table('FCEL_monthly', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recaping on the data we saved from our API request the following structure for each frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted close</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>7.690</td>\n",
       "      <td>8.93</td>\n",
       "      <td>7.670</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>158157913</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>7.260</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.130</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.39</td>\n",
       "      <td>46304186</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-14</td>\n",
       "      <td>7.380</td>\n",
       "      <td>7.44</td>\n",
       "      <td>6.870</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.22</td>\n",
       "      <td>39061771</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>7.200</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.930</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.25</td>\n",
       "      <td>29360583</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>6.745</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.705</td>\n",
       "      <td>6.92</td>\n",
       "      <td>6.92</td>\n",
       "      <td>18894619</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   open  high    low  close  adjusted close     volume  year  \\\n",
       "0 2021-10-18  7.690  8.93  7.670   8.74            8.74  158157913  2021   \n",
       "1 2021-10-15  7.260  7.85  7.130   7.39            7.39   46304186  2021   \n",
       "2 2021-10-14  7.380  7.44  6.870   7.22            7.22   39061771  2021   \n",
       "3 2021-10-13  7.200  7.31  6.930   7.25            7.25   29360583  2021   \n",
       "4 2021-10-12  6.745  7.04  6.705   6.92            6.92   18894619  2021   \n",
       "\n",
       "   month  week  \n",
       "0     10    42  \n",
       "1     10    41  \n",
       "2     10    41  \n",
       "3     10    41  \n",
       "4     10    41  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             datetime64[ns]\n",
       "open                     float64\n",
       "high                     float64\n",
       "low                      float64\n",
       "close                    float64\n",
       "adjusted close           float64\n",
       "volume                     int64\n",
       "year                       int64\n",
       "month                      int64\n",
       "week                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to check which data frequency has the oldest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d['index'] = pd.to_datetime(df_d['index'])\n",
    "df_w['index'] = pd.to_datetime(df_w['index'])\n",
    "df_m['index'] = pd.to_datetime(df_m['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1999-11-01 00:00:00'),\n",
       " Timestamp('1999-11-12 00:00:00'),\n",
       " Timestamp('1999-12-31 00:00:00'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d['index'].min(), df_w['index'].min(), df_m['index'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the full outputsize daily series has the most data, although the others are almost as complete as well and won't present difficulties in the modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For features we are going to start with summarized data for all the six fields by periodicity with 100 data points for daily, 100 data points for weekly and 60 data points for monthly, this should help with all short, mid and long term trends and variances in the asset value and balance the contain information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for achieving those features should be something along this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cols = ['open',\n",
    "            'high',\n",
    "            'low',\n",
    "            'close',\n",
    "            'adjusted close',\n",
    "            'volume']\n",
    "\n",
    "\n",
    "for col in val_cols:\n",
    "    # initialize summarized variables\n",
    "    df_m['mean_'+col] = -999\n",
    "    df_w['mean_'+col] = -999\n",
    "    df_d['mean_'+col] = -999\n",
    "    \n",
    "    # scan the dataframe backwards in time\n",
    "    for i in range(df_d.shape[0]-100):\n",
    "        # assign the mean of the last n observations to the relative entry\n",
    "        df_d.loc[i, 'mean_'+col] = df_d.loc[i:i+100, col].mean()\n",
    "    \n",
    "    # scan the dataframe backwards in time\n",
    "    for i in range(df_w.shape[0]-100):\n",
    "        # assign the mean of the last n observations to the relative entry\n",
    "        df_w.loc[i, 'mean_'+col] = df_w.loc[i:i+100, col].mean()\n",
    "    \n",
    "    # scan the dataframe backwards in time\n",
    "    for i in range(df_m.shape[0]-60):\n",
    "        # assign the mean of the last n observations to the relative entry\n",
    "        df_m.loc[i, 'mean_'+col] = df_m.loc[i:i+60, col].mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted close</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>mean_open</th>\n",
       "      <th>mean_high</th>\n",
       "      <th>mean_low</th>\n",
       "      <th>mean_close</th>\n",
       "      <th>mean_adjusted close</th>\n",
       "      <th>mean_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>7.690</td>\n",
       "      <td>8.93</td>\n",
       "      <td>7.670</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>158157913</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>7.436618</td>\n",
       "      <td>7.716428</td>\n",
       "      <td>7.176482</td>\n",
       "      <td>7.419604</td>\n",
       "      <td>7.419604</td>\n",
       "      <td>2.369202e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>7.260</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.130</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.39</td>\n",
       "      <td>46304186</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>7.443450</td>\n",
       "      <td>7.713952</td>\n",
       "      <td>7.182918</td>\n",
       "      <td>7.416436</td>\n",
       "      <td>7.416436</td>\n",
       "      <td>2.226256e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-14</td>\n",
       "      <td>7.380</td>\n",
       "      <td>7.44</td>\n",
       "      <td>6.870</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.22</td>\n",
       "      <td>39061771</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>7.461063</td>\n",
       "      <td>7.725725</td>\n",
       "      <td>7.193855</td>\n",
       "      <td>7.427426</td>\n",
       "      <td>7.427426</td>\n",
       "      <td>2.201812e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>7.200</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.930</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.25</td>\n",
       "      <td>29360583</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>7.472210</td>\n",
       "      <td>7.741467</td>\n",
       "      <td>7.208806</td>\n",
       "      <td>7.444158</td>\n",
       "      <td>7.444158</td>\n",
       "      <td>2.186002e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>6.745</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.705</td>\n",
       "      <td>6.92</td>\n",
       "      <td>6.92</td>\n",
       "      <td>18894619</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>7.487160</td>\n",
       "      <td>7.756110</td>\n",
       "      <td>7.220390</td>\n",
       "      <td>7.456337</td>\n",
       "      <td>7.456337</td>\n",
       "      <td>2.173841e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   open  high    low  close  adjusted close     volume  year  \\\n",
       "0 2021-10-18  7.690  8.93  7.670   8.74            8.74  158157913  2021   \n",
       "1 2021-10-15  7.260  7.85  7.130   7.39            7.39   46304186  2021   \n",
       "2 2021-10-14  7.380  7.44  6.870   7.22            7.22   39061771  2021   \n",
       "3 2021-10-13  7.200  7.31  6.930   7.25            7.25   29360583  2021   \n",
       "4 2021-10-12  6.745  7.04  6.705   6.92            6.92   18894619  2021   \n",
       "\n",
       "   month  week  mean_open  mean_high  mean_low  mean_close  \\\n",
       "0     10    42   7.436618   7.716428  7.176482    7.419604   \n",
       "1     10    41   7.443450   7.713952  7.182918    7.416436   \n",
       "2     10    41   7.461063   7.725725  7.193855    7.427426   \n",
       "3     10    41   7.472210   7.741467  7.208806    7.444158   \n",
       "4     10    41   7.487160   7.756110  7.220390    7.456337   \n",
       "\n",
       "   mean_adjusted close   mean_volume  \n",
       "0             7.419604  2.369202e+07  \n",
       "1             7.416436  2.226256e+07  \n",
       "2             7.427426  2.201812e+07  \n",
       "3             7.444158  2.186002e+07  \n",
       "4             7.456337  2.173841e+07  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was for the summarized features, now on the daily dataframe we are going to define the objective variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_open', 'mean_high', 'mean_low', 'mean_close',\n",
       "       'mean_adjusted close', 'mean_volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.columns[df_d.columns.str.contains('mean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = ['obj_rise',\n",
    "            'obj_max',\n",
    "            'obj_min']\n",
    "\n",
    "# initialize columns\n",
    "df_d['obj_rise'] = -999\n",
    "df_d['obj_max'] = -999\n",
    "df_d['obj_min'] = -999\n",
    "\n",
    "# scan the dataframe backwards in time\n",
    "for i in range(df_d.shape[0]):\n",
    "    \n",
    "    # define start date as the current index value for the row\n",
    "    start_date = df_d.iloc[i,0]\n",
    "    # define end date as the start date plus 3 months\n",
    "    end_date = start_date + pd.DateOffset(months=3)\n",
    "    \n",
    "    # check if there are entries at or after the end date\n",
    "    if df_d['index'].max() < end_date:\n",
    "        continue\n",
    "    \n",
    "    # get data from start to end date\n",
    "    df_3_month = df_d[(df_d['index']> start_date) & (df_d['index']<= end_date)]\n",
    "    \n",
    "    # assing realization of the minimun and maximun values\n",
    "    df_d.loc[i, 'obj_max'] = df_3_month['close'].max()\n",
    "    df_d.loc[i, 'obj_min'] = df_3_month['close'].min()\n",
    "    \n",
    "    # identify wheter the stock value increase compared to starting price\n",
    "    if df_3_month.tail(1)['close'].values[0] > df_d.loc[i, 'close']:\n",
    "        df_d.loc[i, 'obj_rise'] = 1\n",
    "    else:\n",
    "        df_d.loc[i, 'obj_rise'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted close</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>mean_open</th>\n",
       "      <th>mean_high</th>\n",
       "      <th>mean_low</th>\n",
       "      <th>mean_close</th>\n",
       "      <th>mean_adjusted close</th>\n",
       "      <th>mean_volume</th>\n",
       "      <th>obj_rise</th>\n",
       "      <th>obj_max</th>\n",
       "      <th>obj_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>29.87</td>\n",
       "      <td>30.87</td>\n",
       "      <td>29.87</td>\n",
       "      <td>30.50</td>\n",
       "      <td>732.00</td>\n",
       "      <td>20200</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>27.12</td>\n",
       "      <td>29.25</td>\n",
       "      <td>27.12</td>\n",
       "      <td>29.12</td>\n",
       "      <td>698.88</td>\n",
       "      <td>15600</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>26.37</td>\n",
       "      <td>26.62</td>\n",
       "      <td>26.25</td>\n",
       "      <td>26.50</td>\n",
       "      <td>636.00</td>\n",
       "      <td>5067</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.50</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.25</td>\n",
       "      <td>630.00</td>\n",
       "      <td>4067</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>25.50</td>\n",
       "      <td>26.12</td>\n",
       "      <td>25.25</td>\n",
       "      <td>25.87</td>\n",
       "      <td>620.88</td>\n",
       "      <td>14600</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index   open   high    low  close  adjusted close  volume  year  \\\n",
       "5522 1999-11-05  29.87  30.87  29.87  30.50          732.00   20200  1999   \n",
       "5523 1999-11-04  27.12  29.25  27.12  29.12          698.88   15600  1999   \n",
       "5524 1999-11-03  26.37  26.62  26.25  26.50          636.00    5067  1999   \n",
       "5525 1999-11-02  26.00  26.50  26.00  26.25          630.00    4067  1999   \n",
       "5526 1999-11-01  25.50  26.12  25.25  25.87          620.88   14600  1999   \n",
       "\n",
       "      month  week  mean_open  mean_high  mean_low  mean_close  \\\n",
       "5522     11    44     -999.0     -999.0    -999.0      -999.0   \n",
       "5523     11    44     -999.0     -999.0    -999.0      -999.0   \n",
       "5524     11    44     -999.0     -999.0    -999.0      -999.0   \n",
       "5525     11    44     -999.0     -999.0    -999.0      -999.0   \n",
       "5526     11    44     -999.0     -999.0    -999.0      -999.0   \n",
       "\n",
       "      mean_adjusted close  mean_volume  obj_rise  obj_max  obj_min  \n",
       "5522               -999.0       -999.0         1     56.0    21.94  \n",
       "5523               -999.0       -999.0         1     56.0    21.94  \n",
       "5524               -999.0       -999.0         1     56.0    21.94  \n",
       "5525               -999.0       -999.0         1     56.0    21.94  \n",
       "5526               -999.0       -999.0         1     56.0    21.94  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0      2990\n",
       " 1      2472\n",
       "-999      65\n",
       "Name: obj_rise, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.obj_rise.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems as pretty decently balanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all summarized data was builded for all frequencies/periodicities we merge it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted close</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>close_monthly</th>\n",
       "      <th>adjusted close_monthly</th>\n",
       "      <th>volume_monthly</th>\n",
       "      <th>week_monthly</th>\n",
       "      <th>mean_open_monthly</th>\n",
       "      <th>mean_high_monthly</th>\n",
       "      <th>mean_low_monthly</th>\n",
       "      <th>mean_close_monthly</th>\n",
       "      <th>mean_adjusted close_monthly</th>\n",
       "      <th>mean_volume_monthly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>7.690</td>\n",
       "      <td>8.93</td>\n",
       "      <td>7.670</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>158157913</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>408741564.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.272407</td>\n",
       "      <td>4.342423</td>\n",
       "      <td>2.408536</td>\n",
       "      <td>3.265228</td>\n",
       "      <td>10.984198</td>\n",
       "      <td>2.780146e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>7.260</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.130</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.39</td>\n",
       "      <td>46304186</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>408741564.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.272407</td>\n",
       "      <td>4.342423</td>\n",
       "      <td>2.408536</td>\n",
       "      <td>3.265228</td>\n",
       "      <td>10.984198</td>\n",
       "      <td>2.780146e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-14</td>\n",
       "      <td>7.380</td>\n",
       "      <td>7.44</td>\n",
       "      <td>6.870</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.22</td>\n",
       "      <td>39061771</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>408741564.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.272407</td>\n",
       "      <td>4.342423</td>\n",
       "      <td>2.408536</td>\n",
       "      <td>3.265228</td>\n",
       "      <td>10.984198</td>\n",
       "      <td>2.780146e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>7.200</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.930</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.25</td>\n",
       "      <td>29360583</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>408741564.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.272407</td>\n",
       "      <td>4.342423</td>\n",
       "      <td>2.408536</td>\n",
       "      <td>3.265228</td>\n",
       "      <td>10.984198</td>\n",
       "      <td>2.780146e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>6.745</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.705</td>\n",
       "      <td>6.92</td>\n",
       "      <td>6.92</td>\n",
       "      <td>18894619</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>408741564.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.272407</td>\n",
       "      <td>4.342423</td>\n",
       "      <td>2.408536</td>\n",
       "      <td>3.265228</td>\n",
       "      <td>10.984198</td>\n",
       "      <td>2.780146e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   open  high    low  close  adjusted close     volume  year  \\\n",
       "0 2021-10-18  7.690  8.93  7.670   8.74            8.74  158157913  2021   \n",
       "1 2021-10-15  7.260  7.85  7.130   7.39            7.39   46304186  2021   \n",
       "2 2021-10-14  7.380  7.44  6.870   7.22            7.22   39061771  2021   \n",
       "3 2021-10-13  7.200  7.31  6.930   7.25            7.25   29360583  2021   \n",
       "4 2021-10-12  6.745  7.04  6.705   6.92            6.92   18894619  2021   \n",
       "\n",
       "   month  week  ...  close_monthly  adjusted close_monthly  volume_monthly  \\\n",
       "0     10    42  ...           8.74                    8.74     408741564.0   \n",
       "1     10    41  ...           8.74                    8.74     408741564.0   \n",
       "2     10    41  ...           8.74                    8.74     408741564.0   \n",
       "3     10    41  ...           8.74                    8.74     408741564.0   \n",
       "4     10    41  ...           8.74                    8.74     408741564.0   \n",
       "\n",
       "   week_monthly  mean_open_monthly  mean_high_monthly  mean_low_monthly  \\\n",
       "0          42.0           3.272407           4.342423          2.408536   \n",
       "1          42.0           3.272407           4.342423          2.408536   \n",
       "2          42.0           3.272407           4.342423          2.408536   \n",
       "3          42.0           3.272407           4.342423          2.408536   \n",
       "4          42.0           3.272407           4.342423          2.408536   \n",
       "\n",
       "   mean_close_monthly  mean_adjusted close_monthly mean_volume_monthly  \n",
       "0            3.265228                    10.984198        2.780146e+08  \n",
       "1            3.265228                    10.984198        2.780146e+08  \n",
       "2            3.265228                    10.984198        2.780146e+08  \n",
       "3            3.265228                    10.984198        2.780146e+08  \n",
       "4            3.265228                    10.984198        2.780146e+08  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = df_w.merge(df_m,\n",
    "                         'left',\n",
    "                         left_on = ['year', 'month'],\n",
    "                         right_on = ['year', 'month'],\n",
    "                         suffixes = ('_weekly', '_monthly'))\n",
    "\n",
    "df_features = df_d.merge(df_features,\n",
    "                         'left',\n",
    "                         left_on = ['year', 'week'],\n",
    "                         right_on = ['year', 'week_weekly'],\n",
    "                         suffixes = ('','_weekly'))\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to have some missing values as for the oldest data points there is not enough relative data points in the past and for the most recent data points there is still not a realization of the objective variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_open                      0.000000\n",
       "mean_high                      0.000000\n",
       "mean_low                       0.000000\n",
       "mean_close                     0.000000\n",
       "mean_adjusted close            0.000000\n",
       "mean_volume                    0.000000\n",
       "obj_rise                       0.000000\n",
       "obj_max                        0.000000\n",
       "obj_min                        0.000000\n",
       "mean_open_weekly               0.000905\n",
       "mean_high_weekly               0.000905\n",
       "mean_low_weekly                0.000905\n",
       "mean_close_weekly              0.000905\n",
       "mean_adjusted close_weekly     0.000905\n",
       "mean_volume_weekly             0.000905\n",
       "mean_open_monthly              0.003438\n",
       "mean_high_monthly              0.003438\n",
       "mean_low_monthly               0.003438\n",
       "mean_close_monthly             0.003438\n",
       "mean_adjusted close_monthly    0.003438\n",
       "mean_volume_monthly            0.003438\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = df_features[df_features.columns[(df_features.columns.str.contains('mean')) | (df_features.columns.str.contains('obj'))]]\n",
    "df_features.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_open</th>\n",
       "      <th>mean_high</th>\n",
       "      <th>mean_low</th>\n",
       "      <th>mean_close</th>\n",
       "      <th>mean_adjusted close</th>\n",
       "      <th>mean_volume</th>\n",
       "      <th>obj_rise</th>\n",
       "      <th>obj_max</th>\n",
       "      <th>obj_min</th>\n",
       "      <th>mean_open_weekly</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_low_weekly</th>\n",
       "      <th>mean_close_weekly</th>\n",
       "      <th>mean_adjusted close_weekly</th>\n",
       "      <th>mean_volume_weekly</th>\n",
       "      <th>mean_open_monthly</th>\n",
       "      <th>mean_high_monthly</th>\n",
       "      <th>mean_low_monthly</th>\n",
       "      <th>mean_close_monthly</th>\n",
       "      <th>mean_adjusted close_monthly</th>\n",
       "      <th>mean_volume_monthly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_open  mean_high  mean_low  mean_close  mean_adjusted close  \\\n",
       "5522     -999.0     -999.0    -999.0      -999.0               -999.0   \n",
       "5523     -999.0     -999.0    -999.0      -999.0               -999.0   \n",
       "5524     -999.0     -999.0    -999.0      -999.0               -999.0   \n",
       "5525     -999.0     -999.0    -999.0      -999.0               -999.0   \n",
       "5526     -999.0     -999.0    -999.0      -999.0               -999.0   \n",
       "\n",
       "      mean_volume  obj_rise  obj_max  obj_min  mean_open_weekly  ...  \\\n",
       "5522       -999.0         1     56.0    21.94               NaN  ...   \n",
       "5523       -999.0         1     56.0    21.94               NaN  ...   \n",
       "5524       -999.0         1     56.0    21.94               NaN  ...   \n",
       "5525       -999.0         1     56.0    21.94               NaN  ...   \n",
       "5526       -999.0         1     56.0    21.94               NaN  ...   \n",
       "\n",
       "      mean_low_weekly  mean_close_weekly  mean_adjusted close_weekly  \\\n",
       "5522              NaN                NaN                         NaN   \n",
       "5523              NaN                NaN                         NaN   \n",
       "5524              NaN                NaN                         NaN   \n",
       "5525              NaN                NaN                         NaN   \n",
       "5526              NaN                NaN                         NaN   \n",
       "\n",
       "      mean_volume_weekly  mean_open_monthly  mean_high_monthly  \\\n",
       "5522                 NaN                NaN                NaN   \n",
       "5523                 NaN                NaN                NaN   \n",
       "5524                 NaN                NaN                NaN   \n",
       "5525                 NaN                NaN                NaN   \n",
       "5526                 NaN                NaN                NaN   \n",
       "\n",
       "      mean_low_monthly  mean_close_monthly  mean_adjusted close_monthly  \\\n",
       "5522               NaN                 NaN                          NaN   \n",
       "5523               NaN                 NaN                          NaN   \n",
       "5524               NaN                 NaN                          NaN   \n",
       "5525               NaN                 NaN                          NaN   \n",
       "5526               NaN                 NaN                          NaN   \n",
       "\n",
       "      mean_volume_monthly  \n",
       "5522                  NaN  \n",
       "5523                  NaN  \n",
       "5524                  NaN  \n",
       "5525                  NaN  \n",
       "5526                  NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necesary to eliminate this entries where we don't have features to make predictions, as we are intersted in predicting with recent data and that will always have these summarized features and as for the entries with out objective values, for this stage we are discarding them as we can't tell yet if we are making good predictions or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_null = lambda x: x.replace(-999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_features.apply(decode_null, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_open                      0.018093\n",
       "mean_high                      0.018093\n",
       "mean_low                       0.018093\n",
       "mean_close                     0.018093\n",
       "mean_adjusted close            0.018093\n",
       "mean_volume                    0.018093\n",
       "obj_rise                       0.011760\n",
       "obj_max                        0.011760\n",
       "obj_min                        0.011760\n",
       "mean_open_weekly               0.087751\n",
       "mean_high_weekly               0.087751\n",
       "mean_low_weekly                0.087751\n",
       "mean_close_weekly              0.087751\n",
       "mean_adjusted close_weekly     0.087751\n",
       "mean_volume_weekly             0.087751\n",
       "mean_open_monthly              0.230686\n",
       "mean_high_monthly              0.230686\n",
       "mean_low_monthly               0.230686\n",
       "mean_close_monthly             0.230686\n",
       "mean_adjusted close_monthly    0.230686\n",
       "mean_volume_monthly            0.230686\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4187, 21)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That would be pretty much all the process to get the features, so let's pack all this in some modules to make it reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadStockFeatures(BaseEstimator, TransformerMixin):\n",
    "    def load_freq_data(self, stock_symbol, freq):\n",
    "        \"\"\"\n",
    "        Load stock_symbol data for the defined frequency.\n",
    "        \"\"\"\n",
    "        engine = create_engine('sqlite:///'+'stock_price.db')\n",
    "        df = pd.read_sql_table(stock_symbol + '_' + freq, engine)\n",
    "        df['index'] = pd.to_datetime(df['index'])\n",
    "        return df\n",
    "    \n",
    "    def build_summarized_features(self, df, n_points):\n",
    "        \"\"\"\n",
    "        Get the mean of the last n_points for the value columns\n",
    "        \"\"\"\n",
    "        \n",
    "        val_cols = ['open',\n",
    "                    'high',\n",
    "                    'low',\n",
    "                    'close',\n",
    "                    'adjusted close',\n",
    "                    'volume']\n",
    "        \n",
    "        # initialize the mean columns\n",
    "        for col in val_cols:\n",
    "            df['mean_'+col] = -999\n",
    "            \n",
    "            # scan the dataframe backwards in time\n",
    "            for i in range(df.shape[0]-n_points):\n",
    "                # assign the mean of the last n observations to the relative entry\n",
    "                df.loc[i, 'mean_'+col] = df.loc[i:i+n_points, col].mean()\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def build_obj_vals(self, df, f_months):\n",
    "        # initialize columns\n",
    "        df['obj_rise'] = -999\n",
    "        df['obj_max'] = -999\n",
    "        df['obj_min'] = -999\n",
    "        \n",
    "        # scan the dataframe backwards in time\n",
    "        for i in range(df.shape[0]):\n",
    "            \n",
    "            # assing start and end date\n",
    "            start_date = df.iloc[i,0]\n",
    "            end_date = start_date + pd.DateOffset(months=f_months)\n",
    "            \n",
    "            # check if there are entries at or after the end date\n",
    "            if df['index'].max() < end_date:\n",
    "                continue\n",
    "            # get data from start to end date\n",
    "            df_3_month = df[(df['index']> start_date) & (df['index']<= end_date)]\n",
    "            \n",
    "            # assing realization of the minimun and maximun values\n",
    "            df.loc[i, 'obj_max'] = df_3_month['close'].max()\n",
    "            df.loc[i, 'obj_min'] = df_3_month['close'].min()\n",
    "            \n",
    "            # identify wheter the stock value increase compared to starting price\n",
    "            if df_3_month.tail(1)['close'].values[0] > df.loc[i, 'close']:\n",
    "                df.loc[i, 'obj_rise'] = 1\n",
    "            else:\n",
    "                df.loc[i, 'obj_rise'] = 0\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def decode_nulls(self, df):\n",
    "        \"\"\"\n",
    "        Replace initialized only values in the data with np.nan.\n",
    "        \"\"\"\n",
    "        decode_null = lambda x: x.replace(-999, np.nan)\n",
    "        df = df.apply(decode_null, axis = 1)\n",
    "        return df\n",
    "    \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, stock_symbol, n_day = 100, n_week = 100, n_month = 60, f_months = 3):\n",
    "        \"\"\"\n",
    "        Run complete feature and objetive values building process for stock_symbol.\n",
    "        \"\"\"\n",
    "        df_d = self.load_freq_data(stock_symbol, 'daily')\n",
    "        df_w = self.load_freq_data(stock_symbol, 'weekly')\n",
    "        df_m = self.load_freq_data(stock_symbol, 'monthly')\n",
    "        print('Loaded time series for the symbol...')\n",
    "        \n",
    "        df_d = self.build_summarized_features(df_d, n_day)\n",
    "        df_w = self.build_summarized_features(df_w, n_week)\n",
    "        df_m = self.build_summarized_features(df_m, n_month)\n",
    "        print('Builded sumarized features for the symbol...')\n",
    "        \n",
    "        df_d = self.build_obj_vals(df_d, f_months)\n",
    "        print('Builded objetive variables for the symbol...')\n",
    "        \n",
    "        df = df_w.merge(df_m,\n",
    "                         'left',\n",
    "                         left_on = ['year', 'month'],\n",
    "                         right_on = ['year', 'month'],\n",
    "                         suffixes = ('_weekly', '_monthly'))\n",
    "        df = df_d.merge(df,\n",
    "                        'left',\n",
    "                        left_on = ['year', 'week'],\n",
    "                        right_on = ['year', 'week_weekly'],\n",
    "                        suffixes = ('','_weekly'))\n",
    "        print('Merged all relevant data...')\n",
    "        df = df[df.columns[(df.columns.str.contains('mean')) | (df.columns.str.contains('obj'))]]\n",
    "        df = self.decode_nulls(df)\n",
    "        print('Decoded null entries...')\n",
    "        \n",
    "        df = df.dropna()\n",
    "        print('Dropped null entries...')\n",
    "        print(' Succesfully loaded symbol features!')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "--- 16.96144962310791 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "lsf = LoadStockFeatures()\n",
    "start_time = time.time()\n",
    "df = lsf.transform('AAPL', f_months = 1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4232, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All though the LoadStockFeatures class is created as a sklearn estimator object, is unlikely we are going to use it within a sklearn pipeline, because we can't feed this object train and testing sets separately, nevertheless this class will prove usefull in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build ML pipeline and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make tasks easier facing forward we are going to build an object that allows to run a full train, predict process on the same data for all of our objective variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierRegressorCombo():\n",
    "    \"\"\"\n",
    "    Combination of classifier and regressor object to predict over the same features.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "    def __init__(self, df, clf = RandomForestClassifier(), reg = RandomForestRegressor(), clf_acc = 0, r2_max = 0, r2_min = 0):\n",
    "        self.df = df\n",
    "        self.clf = clf\n",
    "        self.reg = reg\n",
    "        self.clf_acc = clf_acc\n",
    "        self.r2_max = r2_max\n",
    "        self.r2_min = r2_min\n",
    "    \n",
    "    def set_df(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Run fitting process for classifier and regressor objects.\n",
    "        \"\"\"\n",
    "        X = self.df[self.df.columns[self.df.columns.str.contains('mean')]]\n",
    "        clf_y = self.df['obj_rise']\n",
    "        reg_y = self.df[['obj_max','obj_min']]\n",
    "        self.clf.fit(X, clf_y)\n",
    "        self.reg.fit(X, reg_y)\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Run predict method for classifier and regressor objects.\n",
    "        \"\"\"\n",
    "        X = self.df[self.df.columns[self.df.columns.str.contains('mean')]]\n",
    "        clf_pred = self.clf.predict(X)\n",
    "        reg_pred = self.reg.predict(X)\n",
    "        return clf_pred, reg_pred\n",
    "    \n",
    "    def clf_report(self, clf_true, clf_pred):\n",
    "        \"\"\"\n",
    "        Get metrics for the classifier.\n",
    "        \"\"\"\n",
    "        print(classification_report(clf_true, clf_pred))\n",
    "        self.clf_acc = accuracy_score(clf_true, clf_pred)\n",
    "        \n",
    "    def reg_report(self, reg_true, reg_pred):\n",
    "        \"\"\"\n",
    "        Get metrics for the regressor.\n",
    "        \"\"\"\n",
    "        print(\" R2 for the maximum value regression: {}\".format(r2_score(reg_true['obj_max'], reg_pred[:, 0])))\n",
    "        self.r2_max = r2_score(reg_true['obj_max'], reg_pred[:, 0])\n",
    "        print(\" R2 for the minimun value regression: {}\".format(r2_score(reg_true['obj_min'], reg_pred[:, 1])))     \n",
    "        self.r2_min = r2_score(reg_true['obj_min'], reg_pred[:, 1])\n",
    "    def full_test(self):\n",
    "        \"\"\"\n",
    "        Train, predict and get metrics for the classifier and regressor.\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        # split data into test and testing sets\n",
    "        df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "        print(\"Splited train and test sets...\")\n",
    "        \n",
    "        # use training data for fitting method\n",
    "        self.set_df(df_train)\n",
    "        self.fit()\n",
    "        print(\"Trained models on train set...\")\n",
    "        \n",
    "        # use testing data for predict method\n",
    "        self.set_df(df_test)        \n",
    "        clf_pred, reg_pred = self.predict()\n",
    "        \n",
    "        # display and store evaluation metrics\n",
    "        print(\"Predicted on test set...\")\n",
    "        print(\"Classification Report: {}\".format(self.clf.__class__.__name__))\n",
    "        self.clf_report(df_test['obj_rise'], clf_pred)\n",
    "        \n",
    "        try:\n",
    "            print(\"Regresion Report: {}\".format(self.reg.estimator.__class__.__name__))\n",
    "        except:\n",
    "            print(\"Regresion Report: {}\".format(self.reg.__class__.__name__))\n",
    "            \n",
    "        self.reg_report(df_test[['obj_max','obj_min']], reg_pred)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.48      0.45       380\n",
      "         1.0       0.54      0.49      0.52       467\n",
      "\n",
      "    accuracy                           0.49       847\n",
      "   macro avg       0.49      0.49      0.48       847\n",
      "weighted avg       0.49      0.49      0.49       847\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.993125866989895\n",
      " R2 for the minimun value regression: 0.9995979372678829\n"
     ]
    }
   ],
   "source": [
    "clf_reg = ClassifierRegressorCombo(df = df)\n",
    "clf_reg.full_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our class for testing both model at the same time, we can go ahead and test for multiple models and evaluate their performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to evaluate\n",
    "clfs = [RandomForestClassifier(), \n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(), \n",
    "        GradientBoostingClassifier(),\n",
    "        MLPClassifier(),\n",
    "        SVC()]\n",
    "\n",
    "regs = [RandomForestRegressor(),\n",
    "        MultiOutputRegressor(AdaBoostRegressor()),\n",
    "        BaggingRegressor(),\n",
    "        MultiOutputRegressor(GradientBoostingRegressor()),\n",
    "        MultiOutputRegressor(MLPRegressor()),\n",
    "        MultiOutputRegressor(SVR())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- MODELS FOR FCEL  ---------\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.57      0.55       464\n",
      "         1.0       0.41      0.36      0.38       374\n",
      "\n",
      "    accuracy                           0.48       838\n",
      "   macro avg       0.47      0.47      0.47       838\n",
      "weighted avg       0.47      0.48      0.47       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.999281719091518\n",
      " R2 for the minimun value regression: 0.9984708067489484\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.84      0.67       464\n",
      "         1.0       0.48      0.18      0.26       374\n",
      "\n",
      "    accuracy                           0.55       838\n",
      "   macro avg       0.52      0.51      0.47       838\n",
      "weighted avg       0.52      0.55      0.49       838\n",
      "\n",
      "Regresion Report: AdaBoostRegressor\n",
      " R2 for the maximum value regression: 0.9412946877351916\n",
      " R2 for the minimun value regression: 0.9433495444983969\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.61      0.56       464\n",
      "         1.0       0.39      0.30      0.34       374\n",
      "\n",
      "    accuracy                           0.47       838\n",
      "   macro avg       0.45      0.46      0.45       838\n",
      "weighted avg       0.46      0.47      0.46       838\n",
      "\n",
      "Regresion Report: BaggingRegressor\n",
      " R2 for the maximum value regression: 0.9981926775467976\n",
      " R2 for the minimun value regression: 0.9986618263999314\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.84      0.66       464\n",
      "         1.0       0.41      0.13      0.20       374\n",
      "\n",
      "    accuracy                           0.53       838\n",
      "   macro avg       0.48      0.49      0.43       838\n",
      "weighted avg       0.48      0.53      0.46       838\n",
      "\n",
      "Regresion Report: GradientBoostingRegressor\n",
      " R2 for the maximum value regression: 0.9935030841523858\n",
      " R2 for the minimun value regression: 0.9931983210892831\n",
      "\n",
      "\n",
      "Splited train and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: MLPClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      1.00      0.71       464\n",
      "         1.0       0.50      0.00      0.01       374\n",
      "\n",
      "    accuracy                           0.55       838\n",
      "   macro avg       0.53      0.50      0.36       838\n",
      "weighted avg       0.53      0.55      0.40       838\n",
      "\n",
      "Regresion Report: MLPRegressor\n",
      " R2 for the maximum value regression: -2210809.8537143483\n",
      " R2 for the minimun value regression: -11220050.29499832\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.93      0.70       464\n",
      "         1.0       0.51      0.09      0.15       374\n",
      "\n",
      "    accuracy                           0.55       838\n",
      "   macro avg       0.53      0.51      0.43       838\n",
      "weighted avg       0.54      0.55      0.46       838\n",
      "\n",
      "Regresion Report: SVR\n",
      " R2 for the maximum value regression: 0.7711876803834243\n",
      " R2 for the minimun value regression: 0.7166233809296103\n",
      "\n",
      "\n",
      "--------- MODELS FOR AAPL  ---------\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.47      0.49       417\n",
      "         1.0       0.53      0.59      0.55       421\n",
      "\n",
      "    accuracy                           0.53       838\n",
      "   macro avg       0.53      0.53      0.52       838\n",
      "weighted avg       0.53      0.53      0.52       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9849410866346083\n",
      " R2 for the minimun value regression: 0.9998647627488182\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.26      0.34       417\n",
      "         1.0       0.51      0.75      0.60       421\n",
      "\n",
      "    accuracy                           0.51       838\n",
      "   macro avg       0.51      0.50      0.47       838\n",
      "weighted avg       0.51      0.51      0.47       838\n",
      "\n",
      "Regresion Report: AdaBoostRegressor\n",
      " R2 for the maximum value regression: 0.9580578409518647\n",
      " R2 for the minimun value regression: 0.9676562642636402\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.49      0.50       417\n",
      "         1.0       0.51      0.52      0.51       421\n",
      "\n",
      "    accuracy                           0.51       838\n",
      "   macro avg       0.51      0.51      0.51       838\n",
      "weighted avg       0.51      0.51      0.51       838\n",
      "\n",
      "Regresion Report: BaggingRegressor\n",
      " R2 for the maximum value regression: 0.982838565389929\n",
      " R2 for the minimun value regression: 0.9998212940012283\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.25      0.35       417\n",
      "         1.0       0.52      0.79      0.63       421\n",
      "\n",
      "    accuracy                           0.52       838\n",
      "   macro avg       0.53      0.52      0.49       838\n",
      "weighted avg       0.53      0.52      0.49       838\n",
      "\n",
      "Regresion Report: GradientBoostingRegressor\n",
      " R2 for the maximum value regression: 0.9796618854407058\n",
      " R2 for the minimun value regression: 0.9968048060839606\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: MLPClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.66       417\n",
      "         1.0       0.00      0.00      0.00       421\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.25      0.50      0.33       838\n",
      "weighted avg       0.25      0.50      0.33       838\n",
      "\n",
      "Regresion Report: MLPRegressor\n",
      " R2 for the maximum value regression: -14157.799388870082\n",
      " R2 for the minimun value regression: -51131.9355640249\n",
      "\n",
      "\n",
      "Splited train and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       417\n",
      "         1.0       0.50      1.00      0.67       421\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.25      0.50      0.33       838\n",
      "weighted avg       0.25      0.50      0.34       838\n",
      "\n",
      "Regresion Report: SVR\n",
      " R2 for the maximum value regression: 0.056359861786987486\n",
      " R2 for the minimun value regression: 0.0825840821540541\n",
      "\n",
      "\n",
      "--------- MODELS FOR BAC  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.48      0.48       420\n",
      "         1.0       0.47      0.47      0.47       418\n",
      "\n",
      "    accuracy                           0.47       838\n",
      "   macro avg       0.47      0.47      0.47       838\n",
      "weighted avg       0.47      0.47      0.47       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9999173993466514\n",
      " R2 for the minimun value regression: 0.9996863187742354\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.57      0.54       420\n",
      "         1.0       0.53      0.48      0.50       418\n",
      "\n",
      "    accuracy                           0.53       838\n",
      "   macro avg       0.53      0.52      0.52       838\n",
      "weighted avg       0.53      0.53      0.52       838\n",
      "\n",
      "Regresion Report: AdaBoostRegressor\n",
      " R2 for the maximum value regression: 0.9812935212270218\n",
      " R2 for the minimun value regression: 0.9648630324961326\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.55      0.52       420\n",
      "         1.0       0.50      0.45      0.47       418\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.50      0.50      0.50       838\n",
      "weighted avg       0.50      0.50      0.50       838\n",
      "\n",
      "Regresion Report: BaggingRegressor\n",
      " R2 for the maximum value regression: 0.999882192364702\n",
      " R2 for the minimun value regression: 0.9995938626192609\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.45      0.49       420\n",
      "         1.0       0.52      0.60      0.56       418\n",
      "\n",
      "    accuracy                           0.52       838\n",
      "   macro avg       0.52      0.52      0.52       838\n",
      "weighted avg       0.52      0.52      0.52       838\n",
      "\n",
      "Regresion Report: GradientBoostingRegressor\n",
      " R2 for the maximum value regression: 0.9976873870075472\n",
      " R2 for the minimun value regression: 0.996479687984841\n",
      "\n",
      "\n",
      "Splited train and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: MLPClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67       420\n",
      "         1.0       0.00      0.00      0.00       418\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.25      0.50      0.33       838\n",
      "weighted avg       0.25      0.50      0.33       838\n",
      "\n",
      "Regresion Report: MLPRegressor\n",
      " R2 for the maximum value regression: -232030323.6847187\n",
      " R2 for the minimun value regression: -80269925.68089539\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.26      0.35       420\n",
      "         1.0       0.51      0.76      0.61       418\n",
      "\n",
      "    accuracy                           0.51       838\n",
      "   macro avg       0.52      0.51      0.48       838\n",
      "weighted avg       0.52      0.51      0.48       838\n",
      "\n",
      "Regresion Report: SVR\n",
      " R2 for the maximum value regression: 0.8823036840721158\n",
      " R2 for the minimun value regression: 0.730082406502665\n",
      "\n",
      "\n",
      "--------- MODELS FOR M  ---------\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.49      0.48       400\n",
      "         1.0       0.52      0.50      0.51       438\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.50      0.50      0.50       838\n",
      "weighted avg       0.50      0.50      0.50       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9994696598940686\n",
      " R2 for the minimun value regression: 0.9994682560509122\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.44      0.45       400\n",
      "         1.0       0.52      0.55      0.53       438\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.49      0.49      0.49       838\n",
      "weighted avg       0.49      0.50      0.50       838\n",
      "\n",
      "Regresion Report: AdaBoostRegressor\n",
      " R2 for the maximum value regression: 0.9497189549161824\n",
      " R2 for the minimun value regression: 0.9596699638027074\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.59      0.55       400\n",
      "         1.0       0.56      0.49      0.52       438\n",
      "\n",
      "    accuracy                           0.54       838\n",
      "   macro avg       0.54      0.54      0.54       838\n",
      "weighted avg       0.54      0.54      0.53       838\n",
      "\n",
      "Regresion Report: BaggingRegressor\n",
      " R2 for the maximum value regression: 0.9994025557816896\n",
      " R2 for the minimun value regression: 0.9993356039340096\n",
      "\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.47      0.47       400\n",
      "         1.0       0.52      0.53      0.53       438\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.50      0.50      0.50       838\n",
      "weighted avg       0.50      0.50      0.50       838\n",
      "\n",
      "Regresion Report: GradientBoostingRegressor\n",
      " R2 for the maximum value regression: 0.9956591847283629\n",
      " R2 for the minimun value regression: 0.9953130730957747\n",
      "\n",
      "\n",
      "Splited train and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: MLPClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65       400\n",
      "         1.0       0.00      0.00      0.00       438\n",
      "\n",
      "    accuracy                           0.48       838\n",
      "   macro avg       0.24      0.50      0.32       838\n",
      "weighted avg       0.23      0.48      0.31       838\n",
      "\n",
      "Regresion Report: MLPRegressor\n",
      " R2 for the maximum value regression: -398201.09050574264\n",
      " R2 for the minimun value regression: -387198.5949219124\n",
      "\n",
      "\n",
      "Splited train and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.63      0.54       400\n",
      "         1.0       0.50      0.34      0.41       438\n",
      "\n",
      "    accuracy                           0.48       838\n",
      "   macro avg       0.49      0.49      0.47       838\n",
      "weighted avg       0.49      0.48      0.47       838\n",
      "\n",
      "Regresion Report: SVR\n",
      " R2 for the maximum value regression: 0.7240959179210604\n",
      " R2 for the minimun value regression: 0.684980262256143\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  initialize metrics dictionary\n",
    "model_select_dict = {'symbol':[],\n",
    "                     'classifier':[],\n",
    "                     'classfication accuracy':[],\n",
    "                     'regressor':[],\n",
    "                     'r2 score for max value':[],\n",
    "                     'r2 score for min value':[],\n",
    "                     'time':[]}\n",
    "\n",
    "symbols = ['FCEL', 'AAPL', 'BAC', 'M']\n",
    "\n",
    "for symbol in symbols:\n",
    "    \n",
    "    # instantiate object for feature retrieving\n",
    "    lsf = LoadStockFeatures()\n",
    "    print('--------- MODELS FOR {}  ---------'.format(symbol))\n",
    "    # get features\n",
    "    df = lsf.transform(symbol)\n",
    "    for clf, reg in zip(clfs, regs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # instantiate classifier and regressor combination object\n",
    "        clf_reg = ClassifierRegressorCombo(df = df, clf = clf, reg = reg)\n",
    "        \n",
    "        # run train test evaluate process\n",
    "        clf_reg.full_test()\n",
    "        \n",
    "        # append data to the metric dictionary\n",
    "        model_select_dict['symbol'].append(symbol)\n",
    "        model_select_dict['classifier'].append(clf_reg.clf.__class__.__name__)\n",
    "        model_select_dict['classfication accuracy'].append(clf_reg.clf_acc)\n",
    "        \n",
    "        # check for regression estimators wrapped in multioutput object\n",
    "        try:\n",
    "            model_select_dict['regressor'].append(clf_reg.reg.estimator.__class__.__name__)\n",
    "        except:\n",
    "            model_select_dict['regressor'].append(clf_reg.reg.__class__.__name__)\n",
    "        \n",
    "        model_select_dict['r2 score for max value'].append(clf_reg.r2_max)\n",
    "        model_select_dict['r2 score for min value'].append(clf_reg.r2_min)      \n",
    "        \n",
    "        model_select_dict['time'].append(time.time() - start_time)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>classifier</th>\n",
       "      <th>classfication accuracy</th>\n",
       "      <th>regressor</th>\n",
       "      <th>r2 score for max value</th>\n",
       "      <th>r2 score for min value</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.478520</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>9.992817e-01</td>\n",
       "      <td>9.984708e-01</td>\n",
       "      <td>3.007023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.546539</td>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>9.412947e-01</td>\n",
       "      <td>9.433495e-01</td>\n",
       "      <td>1.038254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.472554</td>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>9.981927e-01</td>\n",
       "      <td>9.986618e-01</td>\n",
       "      <td>0.588603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.526253</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>9.935031e-01</td>\n",
       "      <td>9.931983e-01</td>\n",
       "      <td>2.949513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.553699</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>-2.210810e+06</td>\n",
       "      <td>-1.122005e+07</td>\n",
       "      <td>4.302970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                  classifier  classfication accuracy  \\\n",
       "0   FCEL      RandomForestClassifier                0.478520   \n",
       "1   FCEL          AdaBoostClassifier                0.546539   \n",
       "2   FCEL           BaggingClassifier                0.472554   \n",
       "3   FCEL  GradientBoostingClassifier                0.526253   \n",
       "4   FCEL               MLPClassifier                0.553699   \n",
       "\n",
       "                   regressor  r2 score for max value  r2 score for min value  \\\n",
       "0      RandomForestRegressor            9.992817e-01            9.984708e-01   \n",
       "1          AdaBoostRegressor            9.412947e-01            9.433495e-01   \n",
       "2           BaggingRegressor            9.981927e-01            9.986618e-01   \n",
       "3  GradientBoostingRegressor            9.935031e-01            9.931983e-01   \n",
       "4               MLPRegressor           -2.210810e+06           -1.122005e+07   \n",
       "\n",
       "       time  \n",
       "0  3.007023  \n",
       "1  1.038254  \n",
       "2  0.588603  \n",
       "3  2.949513  \n",
       "4  4.302970  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_select_df = pd.DataFrame(model_select_dict)\n",
    "model_select_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>classifier</th>\n",
       "      <th>classfication accuracy</th>\n",
       "      <th>regressor</th>\n",
       "      <th>r2 score for max value</th>\n",
       "      <th>r2 score for min value</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.553699</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>-2.210810e+06</td>\n",
       "      <td>-1.122005e+07</td>\n",
       "      <td>4.302970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.497613</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>-1.415780e+04</td>\n",
       "      <td>-5.113194e+04</td>\n",
       "      <td>3.868173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BAC</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.501193</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>-2.320303e+08</td>\n",
       "      <td>-8.026993e+07</td>\n",
       "      <td>5.899026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>M</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.477327</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>-3.982011e+05</td>\n",
       "      <td>-3.871986e+05</td>\n",
       "      <td>4.309250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol     classifier  classfication accuracy     regressor  \\\n",
       "4    FCEL  MLPClassifier                0.553699  MLPRegressor   \n",
       "10   AAPL  MLPClassifier                0.497613  MLPRegressor   \n",
       "16    BAC  MLPClassifier                0.501193  MLPRegressor   \n",
       "22      M  MLPClassifier                0.477327  MLPRegressor   \n",
       "\n",
       "    r2 score for max value  r2 score for min value      time  \n",
       "4            -2.210810e+06           -1.122005e+07  4.302970  \n",
       "10           -1.415780e+04           -5.113194e+04  3.868173  \n",
       "16           -2.320303e+08           -8.026993e+07  5.899026  \n",
       "22           -3.982011e+05           -3.871986e+05  4.309250  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_select_df[model_select_df['r2 score for max value'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of points it's definitely not ideal for the MLPRegressor, so for now we are going to inpute this r2 scores with `0` strictly for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select_df['r2 score for max value'] = np.where(model_select_df['r2 score for max value'] < 0,\n",
    "                                                     0,\n",
    "                                                     model_select_df['r2 score for max value'])\n",
    "model_select_df['r2 score for min value'] = np.where(model_select_df['r2 score for min value'] < 0,\n",
    "                                                     0,\n",
    "                                                     model_select_df['r2 score for min value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1bed37ad1c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 493.5x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.catplot(data=model_select_df, \n",
    "                kind=\"bar\", \n",
    "                x=\"classifier\", \n",
    "                y=\"classfication accuracy\", \n",
    "                hue=\"symbol\", \n",
    "                alpha=.6,\n",
    "                height=6);\n",
    "g.legend.set_title(\"\")\n",
    "g.set_xticklabels(rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1bed493d520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 925.5x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.catplot(data=pd.melt(model_select_df, id_vars=['symbol','regressor'], \n",
    "                             value_vars=['r2 score for max value', 'r2 score for min value']), \n",
    "                kind=\"bar\", \n",
    "                x=\"regressor\", \n",
    "                y=\"value\",\n",
    "                col = 'variable',\n",
    "                hue=\"symbol\", \n",
    "                alpha=.6,\n",
    "                height=6);\n",
    "g.legend.set_title(\"\")\n",
    "g.set_xticklabels(rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time of excecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 601.25x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.catplot(data=model_select_df, \n",
    "                kind=\"bar\", \n",
    "                x=\"symbol\", \n",
    "                y=\"time\", \n",
    "                hue=\"classifier\", \n",
    "                alpha=.6,\n",
    "                height=6);\n",
    "g.legend.set_title(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Performing Estimator by Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCEL -- classifier: SVC. regressor: RandomForestRegressor\n",
      "AAPL -- classifier: RandomForestClassifier. regressor: RandomForestRegressor\n",
      "BAC -- classifier: AdaBoostClassifier. regressor: RandomForestRegressor\n",
      "M -- classifier: BaggingClassifier. regressor: RandomForestRegressor\n"
     ]
    }
   ],
   "source": [
    "for symbol in symbols:\n",
    "    clf = list(model_select_df[model_select_df['symbol']==symbol]. \\\n",
    "               sort_values('classfication accuracy',\n",
    "                           ascending = False)['classifier'])[0]\n",
    "    reg = list(model_select_df[model_select_df['symbol']==symbol]. \\\n",
    "               sort_values('r2 score for max value',\n",
    "                           ascending = False)['regressor'])[0]\n",
    "    print(\"{} -- classifier: {}. regressor: {}\".format(symbol, clf, reg))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Estimators On Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier\n",
       "GradientBoostingClassifier    0.518795\n",
       "AdaBoostClassifier            0.518496\n",
       "SVC                           0.511933\n",
       "MLPClassifier                 0.507458\n",
       "BaggingClassifier             0.503282\n",
       "RandomForestClassifier        0.493735\n",
       "Name: classfication accuracy, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_select_df.groupby(by = 'classifier').mean()['classfication accuracy'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2 score for max value</th>\n",
       "      <th>r2 score for min value</th>\n",
       "      <th>avg r2 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regressor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.995902</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.997638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.995079</td>\n",
       "      <td>0.999353</td>\n",
       "      <td>0.997216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.991628</td>\n",
       "      <td>0.995449</td>\n",
       "      <td>0.993538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.957591</td>\n",
       "      <td>0.958885</td>\n",
       "      <td>0.958238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.608487</td>\n",
       "      <td>0.553568</td>\n",
       "      <td>0.581027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           r2 score for max value  r2 score for min value  \\\n",
       "regressor                                                                   \n",
       "RandomForestRegressor                    0.995902                0.999373   \n",
       "BaggingRegressor                         0.995079                0.999353   \n",
       "GradientBoostingRegressor                0.991628                0.995449   \n",
       "AdaBoostRegressor                        0.957591                0.958885   \n",
       "SVR                                      0.608487                0.553568   \n",
       "MLPRegressor                             0.000000                0.000000   \n",
       "\n",
       "                           avg r2 score  \n",
       "regressor                                \n",
       "RandomForestRegressor          0.997638  \n",
       "BaggingRegressor               0.997216  \n",
       "GradientBoostingRegressor      0.993538  \n",
       "AdaBoostRegressor              0.958238  \n",
       "SVR                            0.581027  \n",
       "MLPRegressor                   0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_model = model_select_df.groupby(by = 'regressor').mean()[['r2 score for max value', 'r2 score for min value']]\n",
    "aux_model['avg r2 score'] = aux_model.apply(np.mean, axis = 1)\n",
    "aux_model.sort_values(by = 'avg r2 score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of the optimization process, only one parameter dictionary for classification and regressor estimator, we are going to pick the same model type across all stocks. Also the there is not to much relative difference between the best on average accross all stock vs the best performing per stock.\n",
    "\n",
    "So we are going to use the following estimators\n",
    "\n",
    "`GradientBoostingClassifier` and `RandomForestRegressor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Features.\n",
    "\n",
    "Looking to further improve the classification results we are goint to include some extra features, as the original features are not being enough.\n",
    "\n",
    "We are going to extend the LoadStockFeatures class to include two more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Average of the last 100 daily returns of the stock.\n",
    "\n",
    "$$ \\mu_t: \\text{return for the day }t \\qquad S_t: \\text{Stock value at day } t$$\n",
    "\n",
    "$$ \\mu_0:= 0  \\qquad \\mu_t :=ln\\left(\\frac{S_t}{S_{t-1}}\\right) $$\n",
    "\n",
    "$$ \\hat\\mu_n(t) = \\frac{\\sum_{i = 1}^n \\mu_{t-i}}{n} $$\n",
    "\n",
    "This returns are the main modeling tool in the [modern portafolio theory.](https://www.jstor.org/stable/2975974)\n",
    "### 3.2 Percentage of the last 100 days that the stock is below the current value.\n",
    "\n",
    "$$ P_{n}(t): \\text{percentage of the last } n \\text{ days at time }t \\text{ that the stock is below the current value } S_t$$\n",
    "$$ P_{n}(t) = \\frac{\\sum_{i = 1}^{n}I_{\\left(-\\infty, S_t\\right)}\\left(S_{t-i}\\right)}{n} $$\n",
    "\n",
    "As the classification can be interpreted as predicting a bernoulli random variable, this feature would correspond to the maximum likelihood estimator for the mean of that variable, given the sample of the last 100 days.\n",
    "\n",
    "### 3.3 Polynomial Features.\n",
    "\n",
    "This type of transformations would allows to include interactions within features and maybe allow the models to grasp better the relevant patterns.\n",
    "\n",
    "For detail info [sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html?highlight=poly#sklearn.preprocessing.PolynomialFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to extent our LoadStockFeatures class with the first to additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadStockFeaturesExtended(LoadStockFeatures):\n",
    "    def build_extended_features(self, df, n_points):\n",
    "        \"\"\"\n",
    "        Get mean return and number of days below actual price for n_points days back.\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialize columns\n",
    "        df['mean_return'] = -999\n",
    "        df['mean_days_below'] = -999\n",
    "        \n",
    "        # scan dataframe backwards in time\n",
    "        for i in range(df.shape[0]-n_points):\n",
    "            \n",
    "            # get the mean return of the last n_points days - only n_points-1 values\n",
    "            df.loc[i, 'mean_return'] = np.mean(np.log(np.divide(np.array(df.loc[i:i+n_points-1, 'close']), \n",
    "                                                                np.array(df.loc[i+1:i+n_points, 'close']))))\n",
    "            # get the mean of the number of days were stock value below current value\n",
    "            df.loc[i, 'mean_days_below'] = np.mean(np.array(df.loc[i:i+n_points-1, 'close'])<df.loc[i, 'close'])\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def transform(self, stock_symbol, n_day = 100, n_week = 100, n_month = 60, f_months = 3):\n",
    "        \"\"\"\n",
    "        Run complete features extended and objetive values building process for stock_symbol.\n",
    "        \"\"\"\n",
    "        df_d = self.load_freq_data(stock_symbol, 'daily')\n",
    "        print(df_d.shape)\n",
    "        df_w = self.load_freq_data(stock_symbol, 'weekly')\n",
    "        df_m = self.load_freq_data(stock_symbol, 'monthly')\n",
    "        print('Loaded time series for the symbol...')\n",
    "        \n",
    "        df_d = self.build_summarized_features(df_d, n_day)\n",
    "        df_d = self.build_extended_features(df_d, n_day)\n",
    "        df_w = self.build_summarized_features(df_w, n_week)\n",
    "        df_m = self.build_summarized_features(df_m, n_month)\n",
    "        print('Builded sumarized features for the symbol...')\n",
    "        \n",
    "        df_d = self.build_obj_vals(df_d, f_months)\n",
    "        print('Builded objetive variables for the symbol...')\n",
    "        \n",
    "        df = df_w.merge(df_m,\n",
    "                         'left',\n",
    "                         left_on = ['year', 'month'],\n",
    "                         right_on = ['year', 'month'],\n",
    "                         suffixes = ('_weekly', '_monthly'))\n",
    "        df = df_d.merge(df,\n",
    "                        'left',\n",
    "                        left_on = ['year', 'week'],\n",
    "                        right_on = ['year', 'week_weekly'],\n",
    "                        suffixes = ('','_weekly'))\n",
    "        print('Merged all relevant data...')\n",
    "        df = df[df.columns[(df.columns.str.contains('mean')) | (df.columns.str.contains('obj'))]]\n",
    "        df = self.decode_nulls(df)\n",
    "        print('Decoded null entries...')\n",
    "        \n",
    "        df = df.dropna()\n",
    "        print('Dropped null entries...')\n",
    "        print(' Succesfully loaded symbol features!')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5529, 10)\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "19.991477012634277\n"
     ]
    }
   ],
   "source": [
    "lsef = LoadStockFeaturesExtended()\n",
    "start_time = time.time()\n",
    "df = lsef.transform('AAPL')\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4189, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the regression part is already performing really well, we are not going to add PolynomialFeatures to that part of the pipeline for the sake of simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets inspect how the chosen models perform with each feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------------------------------ AAPL ------------------------------------ \n",
      "\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "\n",
      "----- RESULTS FOR INITIAL FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.27      0.33       393\n",
      "         1.0       0.51      0.68      0.58       445\n",
      "\n",
      "    accuracy                           0.49       838\n",
      "   macro avg       0.47      0.48      0.46       838\n",
      "weighted avg       0.47      0.49      0.47       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9997820139742941\n",
      " R2 for the minimun value regression: 0.9995353812141407\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.27      0.33       393\n",
      "         1.0       0.51      0.68      0.58       445\n",
      "\n",
      "    accuracy                           0.49       838\n",
      "   macro avg       0.47      0.48      0.46       838\n",
      "weighted avg       0.47      0.49      0.47       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9997904832496349\n",
      " R2 for the minimun value regression: 0.9995101778930419\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES WITH POLYNOMIAL TRANSFORMATIONS -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: Pipeline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.27      0.33       393\n",
      "         1.0       0.51      0.67      0.58       445\n",
      "\n",
      "    accuracy                           0.49       838\n",
      "   macro avg       0.47      0.47      0.46       838\n",
      "weighted avg       0.47      0.49      0.46       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9997731707667973\n",
      " R2 for the minimun value regression: 0.999509844204964\n",
      "\n",
      " ------------------------------------ FCEL ------------------------------------ \n",
      "\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "\n",
      "----- RESULTS FOR INITIAL FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.84      0.66       464\n",
      "         1.0       0.41      0.14      0.21       374\n",
      "\n",
      "    accuracy                           0.53       838\n",
      "   macro avg       0.48      0.49      0.43       838\n",
      "weighted avg       0.49      0.53      0.46       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9992152002618534\n",
      " R2 for the minimun value regression: 0.9988388225045974\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.84      0.66       464\n",
      "         1.0       0.41      0.13      0.20       374\n",
      "\n",
      "    accuracy                           0.53       838\n",
      "   macro avg       0.48      0.49      0.43       838\n",
      "weighted avg       0.48      0.53      0.46       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9992346714188364\n",
      " R2 for the minimun value regression: 0.9986246368384321\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES WITH POLYNOMIAL TRANSFORMATIONS -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: Pipeline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.83      0.66       464\n",
      "         1.0       0.46      0.18      0.26       374\n",
      "\n",
      "    accuracy                           0.54       838\n",
      "   macro avg       0.51      0.50      0.46       838\n",
      "weighted avg       0.51      0.54      0.48       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9992139510272974\n",
      " R2 for the minimun value regression: 0.9986819438057751\n",
      "\n",
      " ------------------------------------ BAC ------------------------------------ \n",
      "\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "\n",
      "----- RESULTS FOR INITIAL FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.45      0.49       420\n",
      "         1.0       0.52      0.59      0.55       418\n",
      "\n",
      "    accuracy                           0.52       838\n",
      "   macro avg       0.52      0.52      0.52       838\n",
      "weighted avg       0.52      0.52      0.52       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9999134008551553\n",
      " R2 for the minimun value regression: 0.9996633294825219\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.45      0.49       420\n",
      "         1.0       0.52      0.59      0.55       418\n",
      "\n",
      "    accuracy                           0.52       838\n",
      "   macro avg       0.52      0.52      0.52       838\n",
      "weighted avg       0.52      0.52      0.52       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9999185970399788\n",
      " R2 for the minimun value regression: 0.9996858796357568\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES WITH POLYNOMIAL TRANSFORMATIONS -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: Pipeline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.55      0.54       420\n",
      "         1.0       0.52      0.48      0.50       418\n",
      "\n",
      "    accuracy                           0.52       838\n",
      "   macro avg       0.52      0.52      0.52       838\n",
      "weighted avg       0.52      0.52      0.52       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9999110861944568\n",
      " R2 for the minimun value regression: 0.9996635364899286\n",
      "\n",
      " ------------------------------------ M ------------------------------------ \n",
      "\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "\n",
      "----- RESULTS FOR INITIAL FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.47      0.47       400\n",
      "         1.0       0.52      0.53      0.52       438\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.50      0.50      0.50       838\n",
      "weighted avg       0.50      0.50      0.50       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.99948458617593\n",
      " R2 for the minimun value regression: 0.9992844416400986\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES -----\n",
      "\n",
      "Splited train and test sets...\n",
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.47      0.47       400\n",
      "         1.0       0.52      0.53      0.53       438\n",
      "\n",
      "    accuracy                           0.50       838\n",
      "   macro avg       0.50      0.50      0.50       838\n",
      "weighted avg       0.50      0.50      0.50       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9994552118926332\n",
      " R2 for the minimun value regression: 0.9993714385542872\n",
      "\n",
      "----- RESULTS FOR EXTENDED FEATURES WITH POLYNOMIAL TRANSFORMATIONS -----\n",
      "\n",
      "Splited train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models on train set...\n",
      "Predicted on test set...\n",
      "Classification Report: Pipeline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.51      0.48       400\n",
      "         1.0       0.49      0.44      0.46       438\n",
      "\n",
      "    accuracy                           0.47       838\n",
      "   macro avg       0.47      0.47      0.47       838\n",
      "weighted avg       0.47      0.47      0.47       838\n",
      "\n",
      "Regresion Report: RandomForestRegressor\n",
      " R2 for the maximum value regression: 0.9994496119383157\n",
      " R2 for the minimun value regression: 0.9993342925485643\n"
     ]
    }
   ],
   "source": [
    "lsef = LoadStockFeaturesExtended()\n",
    "lsf = LoadStockFeatures()\n",
    "for symbol in ['AAPL', 'FCEL', 'BAC', 'M']:\n",
    "    print('\\n ------------------------------------ {} ------------------------------------ \\n'.format(symbol))\n",
    "    # get data features for the symbol\n",
    "    df = lsf.transform(symbol)\n",
    "    \n",
    "    clf_reg = ClassifierRegressorCombo(df = df, clf = GradientBoostingClassifier(), reg = RandomForestRegressor())\n",
    "    print('\\n----- RESULTS FOR INITIAL FEATURES -----\\n')\n",
    "    \n",
    "    # run train test evaluate process\n",
    "    clf_reg.full_test()\n",
    "    \n",
    "    # get extended features for the symbol\n",
    "    df = lsef.transform(symbol)\n",
    "    clf_reg = ClassifierRegressorCombo(df = df, clf = GradientBoostingClassifier(), reg = RandomForestRegressor())\n",
    "    print('\\n----- RESULTS FOR EXTENDED FEATURES -----\\n')\n",
    "    \n",
    "    # run train test evaluate process\n",
    "    clf_reg.full_test()\n",
    "    \n",
    "    # define classifier pipeline to add polynomial features on top of the extended ones\n",
    "    clf = Pipeline([('polyfeatures', PolynomialFeatures()),\n",
    "                    ('clf', GradientBoostingClassifier())])\n",
    "    \n",
    "    clf_reg = ClassifierRegressorCombo(df = df, clf = clf, reg = RandomForestRegressor())\n",
    "    print('\\n----- RESULTS FOR EXTENDED FEATURES WITH POLYNOMIAL TRANSFORMATIONS -----\\n')\n",
    "    # run train test evaluate process\n",
    "    clf_reg.full_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Optimization & 5. Model Saving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run grid search optimization on the classifier and regression objects and, because this is very time consuming we are going to stored right away the optimized estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params from the classifier pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('polyfeatures', PolynomialFeatures()),\n",
       "  ('clf', GradientBoostingClassifier())],\n",
       " 'verbose': False,\n",
       " 'polyfeatures': PolynomialFeatures(),\n",
       " 'clf': GradientBoostingClassifier(),\n",
       " 'polyfeatures__degree': 2,\n",
       " 'polyfeatures__include_bias': True,\n",
       " 'polyfeatures__interaction_only': False,\n",
       " 'polyfeatures__order': 'C',\n",
       " 'clf__ccp_alpha': 0.0,\n",
       " 'clf__criterion': 'friedman_mse',\n",
       " 'clf__init': None,\n",
       " 'clf__learning_rate': 0.1,\n",
       " 'clf__loss': 'deviance',\n",
       " 'clf__max_depth': 3,\n",
       " 'clf__max_features': None,\n",
       " 'clf__max_leaf_nodes': None,\n",
       " 'clf__min_impurity_decrease': 0.0,\n",
       " 'clf__min_impurity_split': None,\n",
       " 'clf__min_samples_leaf': 1,\n",
       " 'clf__min_samples_split': 2,\n",
       " 'clf__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__n_estimators': 100,\n",
       " 'clf__n_iter_no_change': None,\n",
       " 'clf__presort': 'deprecated',\n",
       " 'clf__random_state': None,\n",
       " 'clf__subsample': 1.0,\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__validation_fraction': 0.1,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    \"\"\"\n",
    "    Ensemble full regressor and classifier pipelines.\n",
    "    \"\"\"\n",
    "    clf_param_dict = {'clf__max_depth':[2, 3, 5],\n",
    "                      'polyfeatures__interaction_only':(True, False)}\n",
    "    reg_param_dict = {'n_estimators':[75,100,125],\n",
    "                      'max_depth':[3, 6, None]}\n",
    "    \n",
    "    gbc = Pipeline([('polyfeatures',PolynomialFeatures()),\n",
    "                    ('clf', GradientBoostingClassifier())])\n",
    "                    \n",
    "    rfr = RandomForestRegressor() \n",
    "    \n",
    "    clf = GridSearchCV(gbc, param_grid = clf_param_dict)\n",
    "    reg = GridSearchCV(rfr, param_grid = reg_param_dict)\n",
    "    \n",
    "    return clf, reg\n",
    "\n",
    "def save_models(clf, reg, symbol):\n",
    "    \"\"\"\n",
    "    Save models for symbol stock value classification and regression.\n",
    "    \"\"\"\n",
    "    filename = 'models/'+symbol+'_clf.pkl'\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    \n",
    "    filename = 'models/'+symbol+'_reg.pkl'\n",
    "    pickle.dump(reg, open(filename, 'wb'))\n",
    "    \n",
    "    \n",
    "def save_metrics(metric_dict):\n",
    "    engine = create_engine('sqlite:///'+'stock_price.db')\n",
    "    df = pd.DataFrame(metric_dict)\n",
    "    df.to_sql('model_metrics', engine, index = False, if_exists= 'replace')\n",
    "    \n",
    "def main_models():\n",
    "    \n",
    "    symbols = ['AAPL','FCEL','BAC','M']\n",
    "    \n",
    "    # initialize metric dictionary\n",
    "    metric_dict = {'symbol':symbols,\n",
    "                   'classification accuracy':[],\n",
    "                   'r2 score - max':[],\n",
    "                   'r2 score - min':[]}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        print(\"\\n -------- Started Process for {} -------- \\n\".format(symbol))\n",
    "        start_time = time.time()\n",
    "        # instantiate feature extractor object\n",
    "        lsef = LoadStockFeaturesExtended()\n",
    "        # get extended feature set for the symbol\n",
    "        df = lsef.transform(symbol)\n",
    "        \n",
    "        # perform train test test evaluation\n",
    "        df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "        print('Train a test sets splitted')\n",
    "        print('Building models...')\n",
    "        clf, reg = build_models()\n",
    "        \n",
    "        X_train = df_train[df_train.columns[df_train.columns.str.contains('mean')]]\n",
    "        y_clf_train = df_train['obj_rise']\n",
    "        y_reg_train = df_train[['obj_max','obj_min']]\n",
    "        \n",
    "        print('Fitting Classifier...')\n",
    "        clf.fit(X_train, y_clf_train)\n",
    "        print('Fitting Regressor...')\n",
    "        reg.fit(X_train, y_reg_train)\n",
    "    \n",
    "        X_test = df_test[df_test.columns[df_test.columns.str.contains('mean')]]\n",
    "        print('Predicting on testing set...')\n",
    "        y_clf_pred = clf.predict(X_test)\n",
    "        y_reg_pred = reg.predict(X_test)\n",
    "        \n",
    "        # store metrics\n",
    "        metric_dict['classification accuracy'].append(accuracy_score(df_test['obj_rise'], y_clf_pred))\n",
    "        metric_dict['r2 score - max'].append(r2_score(df_test['obj_max'], y_reg_pred[:, 0]))\n",
    "        metric_dict['r2 score - min'].append(r2_score(df_test['obj_min'], y_reg_pred[:, 1]))\n",
    "        \n",
    "        print('Saving models...')\n",
    "        save_models(clf, reg, symbol)\n",
    "        print(\" elapsed time: {}\".format(time.time()- start_time))\n",
    "    print('Saving overall metrics...')\n",
    "    save_metrics(metric_dict)\n",
    "    print('  Training process completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------- Started Process for AAPL -------- \n",
      "\n",
      "(5529, 10)\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Train a test sets splitted\n",
      "Building models...\n",
      "Fitting Classifier...\n",
      "Fitting Regressor...\n",
      "Predicting on testing set...\n",
      "Saving models...\n",
      " elapsed time: 427.4348404407501\n",
      "\n",
      " -------- Started Process for FCEL -------- \n",
      "\n",
      "(5527, 10)\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Train a test sets splitted\n",
      "Building models...\n",
      "Fitting Classifier...\n",
      "Fitting Regressor...\n",
      "Predicting on testing set...\n",
      "Saving models...\n",
      " elapsed time: 449.60519647598267\n",
      "\n",
      " -------- Started Process for BAC -------- \n",
      "\n",
      "(5528, 10)\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Train a test sets splitted\n",
      "Building models...\n",
      "Fitting Classifier...\n",
      "Fitting Regressor...\n",
      "Predicting on testing set...\n",
      "Saving models...\n",
      " elapsed time: 447.01174449920654\n",
      "\n",
      " -------- Started Process for M -------- \n",
      "\n",
      "(5528, 10)\n",
      "Loaded time series for the symbol...\n",
      "Builded sumarized features for the symbol...\n",
      "Builded objetive variables for the symbol...\n",
      "Merged all relevant data...\n",
      "Decoded null entries...\n",
      "Dropped null entries...\n",
      " Succesfully loaded symbol features!\n",
      "Train a test sets splitted\n",
      "Building models...\n",
      "Fitting Classifier...\n",
      "Fitting Regressor...\n",
      "Predicting on testing set...\n",
      "Saving models...\n",
      " elapsed time: 436.20636439323425\n",
      "Saving overall metrics...\n",
      "  Training process completed!\n"
     ]
    }
   ],
   "source": [
    "main_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Predicting on New Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is necesary to test functions to request data and transform it so the stored models can make predictions on int."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is going to be used within the web app to make predictions as requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "\n",
    "def load_series(symbol, frequency, outputsize = 'compact'):\n",
    "    \"\"\"\n",
    "    Load time serie from the stock symbol with the defined frequency and outputsize.\n",
    "    \n",
    "    IN:\n",
    "    symbol -- stock's symbol to get the data.\n",
    "    frequency -- either dayly, weekly or monthly data to be retrieved.\n",
    "    outputsize -- by default compact for last 100 data points in the series or \n",
    "                  full for the complete 20+ years of historical data.\n",
    "    \n",
    "    OUT: pandas dataframe with the following columns:\n",
    "    open -- opening price on the period.\n",
    "    high -- maximun price during the period.\n",
    "    low -- minimum price during the period.\n",
    "    close -- closing price on the period.\n",
    "    adjuste close -- adjusted closing price on the period.\n",
    "    volume -- number of negotiations during the period.\n",
    "    \"\"\"\n",
    "    \n",
    "    # function dictionary for different time series in the API\n",
    "    freq_funct_dict = {'daily':'TIME_SERIES_DAILY_ADJUSTED',\n",
    "                       'weekly':'TIME_SERIES_WEEKLY_ADJUSTED',\n",
    "                       'monthly':'TIME_SERIES_MONTHLY_ADJUSTED'}\n",
    "    \n",
    "    # define the url to make the request\n",
    "    url = 'https://www.alphavantage.co/query?function='+freq_funct_dict[frequency]+'&symbol='+symbol \\\n",
    "        +'&outputsize='+outputsize+'&apikey=F0UT6370FXK949PA'\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    \n",
    "    # build dataframe from data dictionary\n",
    "    df = pd.DataFrame.from_dict(data = data[list(data.keys())[1]], orient='index')\n",
    "    \n",
    "    # adjust columns types and names\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors = 'coerce')\n",
    "    rem_dig = lambda x : re.sub('[1-9]. ', '', x)\n",
    "    df.columns = [rem_dig(x) for x in df.columns]\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df['index'] = pd.to_datetime(df['index'])\n",
    "    \n",
    "    df['year'] = df['index'].dt.year\n",
    "    df['month'] = df['index'].dt.month\n",
    "    df['week'] = df['index'].dt.isocalendar().week\n",
    "    \n",
    "    df = df.set_index('index')\n",
    "    \n",
    "    out_cols = ['open',\n",
    "                'high',\n",
    "                'low',\n",
    "                'close',\n",
    "                'adjusted close',\n",
    "                'volume',\n",
    "                'year',\n",
    "                'month',\n",
    "                'week']\n",
    "    return df[out_cols]\n",
    "\n",
    "def save_pred_data(symbol):\n",
    "    \"\"\"\n",
    "    Save the stock data in the defined database\n",
    "    \"\"\"\n",
    "    engine = create_engine('sqlite:///../stock_price.db')\n",
    "    \n",
    "    # get the day when the request it's being made\n",
    "    day_request = dt.date.today().strftime('%Y%m%d')\n",
    "\n",
    "    for freq in ['daily', 'weekly', 'monthly']:\n",
    "        \n",
    "        # check if there is already data for that stock for the day of the request\n",
    "        try:\n",
    "            df = pd.read_sql_table(stock_symbol + '_' + freq+'_to_predict', engine)\n",
    "            df = df[df['day_request']==day_request]\n",
    "            if df.shape[0] > 0:\n",
    "                print('.. Data already have been requested {}..'.format(day_request))\n",
    "                return None\n",
    "        except:\n",
    "            df = load_series(symbol, freq, outputsize = 'compact')\n",
    "            df['day_request']=day_request\n",
    "            df.to_sql(symbol+'_'+freq+'_to_predict', engine, if_exists = 'replace')\n",
    "\n",
    "class LoadPredFeatures():\n",
    "    def load_freq_data(self, stock_symbol, freq):\n",
    "        \"\"\"\n",
    "        Store stock data at frequency freq for prediction.\n",
    "        \"\"\"\n",
    "        engine = create_engine('sqlite:///'+'stock_price.db')\n",
    "        df = pd.read_sql_table(stock_symbol + '_' + freq+'_to_predict', engine)\n",
    "        df['index'] = pd.to_datetime(df['index'])\n",
    "        return df\n",
    "    \n",
    "    def get_features(self, df, n_points, extended = False):\n",
    "        \"\"\"\n",
    "        Build summarized features plus mean returns and mean days below.\n",
    "        \"\"\"\n",
    "        \n",
    "        # select only the last n_points data points\n",
    "        df = df.head(n_points)\n",
    "        cols = ['open','high','low','close','adjusted close','volume']\n",
    "        \n",
    "        # take the mean of the selected data\n",
    "        df_ = df[cols].apply(np.mean, axis = 0)\n",
    "        df_ = pd.DataFrame(df_).transpose()\n",
    "        \n",
    "        # adjust column names\n",
    "        df_.columns = ['mean_'+col for col in cols]\n",
    "        \n",
    "        # add dummy key for feature union with different frequencies\n",
    "        df_['m_key'] = 1\n",
    "        \n",
    "        if extended:\n",
    "            df_['mean_return'] =np.mean(np.log(np.divide(np.array(df.loc[0:n_points-2, 'close']), \n",
    "                                                         np.array(df.loc[1:n_points-1, 'close']))))\n",
    "\n",
    "            df_['mean_days_below'] = np.mean(np.array(df.loc[:, 'close'])<df.loc[0, 'close'])\n",
    "                    \n",
    "        return df_\n",
    "    \n",
    "    def transform(self, stock_symbol, n_day = 100, n_week = 100, n_month = 60, f_months = 3):\n",
    "        \"\"\"\n",
    "        Run complete feature extedend build process for prediction on stock_symbol.\n",
    "        \"\"\"\n",
    "        df_d = self.load_freq_data(stock_symbol, 'daily')\n",
    "        df_w = self.load_freq_data(stock_symbol, 'weekly')\n",
    "        df_m = self.load_freq_data(stock_symbol, 'monthly')\n",
    "        print('Loaded time series for the symbol...')\n",
    "        \n",
    "        df_d = self.get_features(df_d, n_day, extended = True)\n",
    "        df_w = self.get_features(df_w, n_week)\n",
    "        df_m = self.get_features(df_m, n_month)\n",
    "        print('Builded features for the symbol...')\n",
    "                \n",
    "        df = df_w.merge(df_m,\n",
    "                         'left',\n",
    "                         left_on = 'm_key',\n",
    "                         right_on = 'm_key',\n",
    "                         suffixes = ('_weekly', '_monthly'))\n",
    "        df = df_d.merge(df,\n",
    "                        'left',\n",
    "                        left_on = 'm_key',\n",
    "                        right_on = 'm_key',\n",
    "                        suffixes = ('','_weekly'))\n",
    "        print('Merged Features...')\n",
    "        df = df[df.columns[df.columns.str.contains('mean')]]\n",
    "        print(' Succesfully loaded symbol features!')\n",
    "        return df\n",
    "\n",
    "def load_models(symbol):\n",
    "    \"\"\"\n",
    "    Load previously stored classification and regresion model for the symbol.\n",
    "    \"\"\"\n",
    "    clf = pickle.load(open('models/'+symbol+'_clf.pkl', 'rb'))\n",
    "    reg = pickle.load(open('models/'+symbol+'_reg.pkl', 'rb'))\n",
    "    return clf, reg\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('loaded modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets validate our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AAPL'\n",
    "save_pred_data(symbol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded time series for the symbol...\n",
      "Builded features for the symbol...\n",
      "Merged Features...\n",
      " Succesfully loaded symbol features!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_open</th>\n",
       "      <th>mean_high</th>\n",
       "      <th>mean_low</th>\n",
       "      <th>mean_close</th>\n",
       "      <th>mean_adjusted close</th>\n",
       "      <th>mean_volume</th>\n",
       "      <th>mean_return</th>\n",
       "      <th>mean_days_below</th>\n",
       "      <th>mean_open_weekly</th>\n",
       "      <th>mean_high_weekly</th>\n",
       "      <th>mean_low_weekly</th>\n",
       "      <th>mean_close_weekly</th>\n",
       "      <th>mean_adjusted close_weekly</th>\n",
       "      <th>mean_volume_weekly</th>\n",
       "      <th>mean_open_monthly</th>\n",
       "      <th>mean_high_monthly</th>\n",
       "      <th>mean_low_monthly</th>\n",
       "      <th>mean_close_monthly</th>\n",
       "      <th>mean_adjusted close_monthly</th>\n",
       "      <th>mean_volume_monthly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142.6797</td>\n",
       "      <td>144.004169</td>\n",
       "      <td>141.550117</td>\n",
       "      <td>142.9085</td>\n",
       "      <td>142.810887</td>\n",
       "      <td>78356223.16</td>\n",
       "      <td>0.00185</td>\n",
       "      <td>0.86</td>\n",
       "      <td>205.8419</td>\n",
       "      <td>214.251739</td>\n",
       "      <td>200.896802</td>\n",
       "      <td>208.7821</td>\n",
       "      <td>110.485987</td>\n",
       "      <td>3.738007e+08</td>\n",
       "      <td>184.649917</td>\n",
       "      <td>199.920107</td>\n",
       "      <td>169.754533</td>\n",
       "      <td>184.246667</td>\n",
       "      <td>69.458957</td>\n",
       "      <td>1.004617e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_open   mean_high    mean_low  mean_close  mean_adjusted close  \\\n",
       "0   142.6797  144.004169  141.550117    142.9085           142.810887   \n",
       "\n",
       "   mean_volume  mean_return  mean_days_below  mean_open_weekly  \\\n",
       "0  78356223.16      0.00185             0.86          205.8419   \n",
       "\n",
       "   mean_high_weekly  mean_low_weekly  mean_close_weekly  \\\n",
       "0        214.251739       200.896802           208.7821   \n",
       "\n",
       "   mean_adjusted close_weekly  mean_volume_weekly  mean_open_monthly  \\\n",
       "0                  110.485987        3.738007e+08         184.649917   \n",
       "\n",
       "   mean_high_monthly  mean_low_monthly  mean_close_monthly  \\\n",
       "0         199.920107        169.754533          184.246667   \n",
       "\n",
       "   mean_adjusted close_monthly  mean_volume_monthly  \n",
       "0                    69.458957         1.004617e+09  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpf = LoadPredFeatures()\n",
    "df = lpf.transform(symbol)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, reg = load_models(symbol)\n",
    "\n",
    "y_clf = clf.predict(df)\n",
    "y_reg = reg.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153.02567998399996, 131.98895999999988)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reg[0, 0], y_reg[0, 1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this trained models and modules we are going to build the web app."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
